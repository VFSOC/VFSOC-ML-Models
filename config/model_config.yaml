# VFSOC ML Models Configuration
# GPS Jamming Detection Model Hyperparameters

# Model Selection
model_selection:
  primary_model: "isolation_forest"  # Primary algorithm for production
  ensemble_models: ["isolation_forest", "random_forest", "lstm_autoencoder"]
  comparison_models: ["one_class_svm", "local_outlier_factor"]

# Isolation Forest Configuration (Primary Model)
isolation_forest:
  n_estimators: 200
  max_samples: "auto"  # Use all samples
  contamination: 0.05  # Expected proportion of anomalies (5%)
  max_features: 1.0
  bootstrap: false
  n_jobs: -1
  random_state: 42
  verbose: 0

# Random Forest Configuration (Secondary Model)
random_forest:
  n_estimators: 100
  max_depth: 10
  min_samples_split: 5
  min_samples_leaf: 2
  max_features: "sqrt"
  bootstrap: true
  n_jobs: -1
  random_state: 42
  class_weight: "balanced"

# LSTM Autoencoder Configuration (Deep Learning)
lstm_autoencoder:
  sequence_length: 50  # Number of time steps to look back
  encoding_dim: 32
  lstm_units: [64, 32, 16]  # Encoder layers
  dropout_rate: 0.2
  learning_rate: 0.001
  batch_size: 32
  epochs: 100
  validation_split: 0.2
  early_stopping_patience: 10
  threshold_percentile: 95  # Anomaly threshold

# One-Class SVM Configuration
one_class_svm:
  kernel: "rbf"
  gamma: "scale"
  nu: 0.05  # Upper bound on fraction of outliers
  shrinking: true
  cache_size: 200

# Local Outlier Factor Configuration
local_outlier_factor:
  n_neighbors: 20
  algorithm: "auto"
  leaf_size: 30
  metric: "minkowski"
  p: 2
  contamination: 0.05
  n_jobs: -1

# Ensemble Configuration
ensemble:
  voting_method: "soft"  # soft or hard voting
  weights: [0.4, 0.3, 0.3]  # Weights for [isolation_forest, random_forest, lstm]
  threshold_strategy: "adaptive"  # adaptive or fixed
  confidence_threshold: 0.7

# Model Training Configuration
training:
  test_size: 0.2
  validation_size: 0.15
  random_state: 42
  stratify: false  # For anomaly detection, usually false
  cross_validation:
    enabled: true
    folds: 5
    scoring: ["precision", "recall", "f1", "roc_auc"]

# Feature Selection
feature_selection:
  enabled: true
  method: "recursive_feature_elimination"  # Options: recursive_feature_elimination, mutual_info, chi2
  n_features: 20  # Number of top features to select
  step: 1

# Hyperparameter Tuning
hyperparameter_tuning:
  enabled: true
  method: "random_search"  # Options: grid_search, random_search, bayesian
  n_iter: 50  # For random search
  cv_folds: 3
  n_jobs: -1
  scoring: "f1"

# Model Evaluation Metrics
evaluation:
  metrics:
    - "precision"
    - "recall"
    - "f1_score"
    - "roc_auc"
    - "accuracy"
    - "confusion_matrix"
    - "classification_report"
  
  # Thresholds for production deployment
  performance_thresholds:
    min_precision: 0.90
    min_recall: 0.85
    min_f1_score: 0.87
    max_false_positive_rate: 0.05
    max_inference_time_ms: 100

# Model Persistence
persistence:
  save_format: "pkl"  # Options: pkl, joblib, onnx
  model_directory: "models/trained"
  experiment_tracking: true  # Use MLflow
  versioning: true

# Production Configuration
production:
  batch_inference: true
  real_time_inference: true
  max_batch_size: 1000
  inference_timeout_ms: 200
  model_warm_up: true

# Logging and Monitoring
logging:
  level: "INFO"
  file_logging: true
  console_logging: true
  model_metrics_logging: true
  
monitoring:
  drift_detection: true
  performance_monitoring: true
  alert_thresholds:
    accuracy_drop: 0.05
    prediction_latency_ms: 150 